{
  "metadata": {
    "module": "numpy",
    "description": "NumPy statistics functions for computing statistical measures on arrays",
    "sources": {
      "order_statistics": "numpy/_core/fromnumeric.py",
      "averages_variances": "numpy/_core/fromnumeric.py, numpy/lib/_function_base_impl.py",
      "correlating": "numpy/lib/_function_base_impl.py, numpy/_core/numeric.py",
      "histograms": "numpy/lib/_histograms_impl.py"
    }
  },
  "functions": [
    {
      "name": "numpy.amin",
      "category": "Order statistics",
      "description": "Return the minimum of an array or minimum along an axis",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.amin.html",
      "doc": "numpy.amin(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)\n\nReturn the minimum of an array or minimum along an axis.\n\nParameters\n----------\na : array_like\n    Input data.\naxis : None or int or tuple of ints, optional\n    Axis or axes along which to operate. By default, flattened input is used.\n    If this is a tuple of ints, the minimum is selected over multiple axes,\n    instead of a single axis or all the axes as before.\nout : ndarray, optional\n    Alternative output array in which to place the result. Must be of the same\n    shape and buffer length as the expected output.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result\n    as dimensions with size one. With this option, the result will broadcast\n    correctly against the input array.\ninitial : scalar, optional\n    The maximum value of an output element. Must be present to allow computation\n    on empty slice.\nwhere : array_like of bool, optional\n    Elements to compare for the minimum.\n\nReturns\n-------\namin : ndarray or scalar\n    Minimum of a. If axis is None, the result is a scalar value. If axis is given,\n    the result is an array of dimension a.ndim - 1.\n\nNotes\n-----\nNaN values are propagated, that is if at least one item is NaN, the corresponding\nmin value will be NaN as well. To ignore NaN values (MATLAB behavior), please use\nnanmin.\n\nDon't use amin for element-wise comparison of 2 arrays; when a.shape[0] is 2,\nminimum(a[0], a[1]) is faster than amin(a, axis=0).",
      "code": "# C implementation for performance\n# Return the minimum of an array or minimum along an axis\n#\n# This function is implemented in C as part of NumPy's core multiarray module.\n# The C implementation provides:\n# - Optimized memory access patterns\n# - Efficient array manipulation\n# - Low-level control over data layout\n# - Integration with NumPy's array object internals\n#\n# Source: # C implementation in numpy/_core/src/multiarray/calculation.c\n# Python wrapper:\n@array_function_dispatch(_amin_dispatcher)\ndef amin(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n         where=np._NoValue):\n    \"\"\"\n    Return the minimum of an array or minimum along an axis.\n    \n    `amin` is an alias of `~numpy.min`.\n    \n    See Also\n    --------\n    min : alias of this function\n    ndarray.min : equivalent method\n    nanmin : minimum that ignores NaN values\n    minimum : element-wise minimum of two arrays\n    fmin : element-wise minimum that propagates NaN\n    argmin : indices of minimum values\n    \"\"\"\n    return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n                          keepdims=keepdims, initial=initial, where=where)"
    },
    {
      "name": "numpy.min",
      "category": "Order statistics",
      "description": "Alias for numpy.amin - Return the minimum of an array or minimum along an axis",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.min.html",
      "doc": "numpy.min is an alias for numpy.amin. See numpy.amin for full documentation.",
      "code": "# Alias for amin\nmin = amin"
    },
    {
      "name": "numpy.amax",
      "category": "Order statistics",
      "description": "Return the maximum of an array or maximum along an axis",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.amax.html",
      "doc": "numpy.amax(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)\n\nReturn the maximum of an array or maximum along an axis.\n\nParameters\n----------\na : array_like\n    Input data.\naxis : None or int or tuple of ints, optional\n    Axis or axes along which to operate. By default, flattened input is used.\n    If this is a tuple of ints, the maximum is selected over multiple axes,\n    instead of a single axis or all the axes as before.\nout : ndarray, optional\n    Alternative output array in which to place the result. Must be of the same\n    shape and buffer length as the expected output.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result\n    as dimensions with size one. With this option, the result will broadcast\n    correctly against the input array.\ninitial : scalar, optional\n    The minimum value of an output element. Must be present to allow computation\n    on empty slice.\nwhere : array_like of bool, optional\n    Elements to compare for the maximum.\n\nReturns\n-------\namax : ndarray or scalar\n    Maximum of a. If axis is None, the result is a scalar value. If axis is given,\n    the result is an array of dimension a.ndim - 1.\n\nNotes\n-----\nNaN values are propagated, that is if at least one item is NaN, the corresponding\nmax value will be NaN as well. To ignore NaN values (MATLAB behavior), please use\nnanmax.\n\nDon't use amax for element-wise comparison of 2 arrays; when a.shape[0] is 2,\nmaximum(a[0], a[1]) is faster than amax(a, axis=0).",
      "code": "# C implementation for performance\n# Return the maximum of an array or maximum along an axis\n#\n# This function is implemented in C as part of NumPy's core multiarray module.\n# The C implementation provides:\n# - Optimized memory access patterns\n# - Efficient array manipulation\n# - Low-level control over data layout\n# - Integration with NumPy's array object internals\n#\n# Source: # C implementation in numpy/_core/src/multiarray/calculation.c\n# Python wrapper:\n@array_function_dispatch(_amax_dispatcher)\ndef amax(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n         where=np._NoValue):\n    \"\"\"\n    Return the maximum of an array or maximum along an axis.\n    \n    `amax` is an alias of `~numpy.max`.\n    \n    See Also\n    --------\n    max : alias of this function\n    ndarray.max : equivalent method\n    nanmax : maximum that ignores NaN values\n    maximum : element-wise maximum of two arrays\n    fmax : element-wise maximum that propagates NaN\n    argmax : indices of maximum values\n    \"\"\"\n    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n                          keepdims=keepdims, initial=initial, where=where)"
    },
    {
      "name": "numpy.max",
      "category": "Order statistics",
      "description": "Alias for numpy.amax - Return the maximum of an array or maximum along an axis",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.max.html",
      "doc": "numpy.max is an alias for numpy.amax. See numpy.amax for full documentation.",
      "code": "# Alias for amax\nmax = amax"
    },
    {
      "name": "numpy.nanmin",
      "category": "Order statistics",
      "description": "Return minimum of an array or minimum along an axis, ignoring any NaNs",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.nanmin.html",
      "doc": "numpy.nanmin(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)\n\nReturn minimum of an array or minimum along an axis, ignoring any NaNs.\nWhen all-NaN slices are encountered a RuntimeWarning is raised and NaN is returned for that slice.\n\nParameters\n----------\na : array_like\n    Array containing numbers whose minimum is desired. If a is not an array, a conversion is attempted.\naxis : {int, tuple of int, None}, optional\n    Axis or axes along which the minimum is computed. The default is to compute the minimum of the flattened array.\nout : ndarray, optional\n    Alternate output array in which to place the result. The default is None; if provided, it must have the same shape as the expected output.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\ninitial : scalar, optional\n    The maximum value of an output element. Must be present to allow computation on empty slice.\nwhere : array_like of bool, optional\n    Elements to compare for the minimum.\n\nReturns\n-------\nnanmin : ndarray\n    An array with the same shape as a, with the specified axis removed. If a is a 0-d array, or if axis is None, an ndarray scalar is returned.",
      "code": "# Implementation in numpy/lib/_nanfunctions_impl.py\n@array_function_dispatch(_nanmin_dispatcher)\ndef nanmin(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n           where=np._NoValue):\n    \"\"\"\n    Return minimum of an array or minimum along an axis, ignoring any NaNs.\n    \"\"\"\n    kwargs = {}\n    if initial is not np._NoValue:\n        kwargs['initial'] = initial\n    if where is not np._NoValue:\n        kwargs['where'] = where\n    if type(a) is not mu.ndarray:\n        try:\n            nanmin = a.nanmin\n        except AttributeError:\n            pass\n        else:\n            return nanmin(axis=axis, out=out, keepdims=keepdims, **kwargs)\n    return _nanextremum(np.min, a, axis, out, keepdims, initial, where)"
    },
    {
      "name": "numpy.nanmax",
      "category": "Order statistics",
      "description": "Return the maximum of an array or maximum along an axis, ignoring any NaNs",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.nanmax.html",
      "doc": "numpy.nanmax(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)\n\nReturn the maximum of an array or maximum along an axis, ignoring any NaNs.\nWhen all-NaN slices are encountered a RuntimeWarning is raised and NaN is returned for that slice.\n\nParameters\n----------\na : array_like\n    Array containing numbers whose maximum is desired. If a is not an array, a conversion is attempted.\naxis : {int, tuple of int, None}, optional\n    Axis or axes along which the maximum is computed. The default is to compute the maximum of the flattened array.\nout : ndarray, optional\n    Alternate output array in which to place the result. The default is None; if provided, it must have the same shape as the expected output.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\ninitial : scalar, optional\n    The minimum value of an output element. Must be present to allow computation on empty slice.\nwhere : array_like of bool, optional\n    Elements to compare for the maximum.\n\nReturns\n-------\nnanmax : ndarray\n    An array with the same shape as a, with the specified axis removed. If a is a 0-d array, or if axis is None, an ndarray scalar is returned.",
      "code": "# Implementation in numpy/lib/_nanfunctions_impl.py\n@array_function_dispatch(_nanmax_dispatcher)\ndef nanmax(a, axis=None, out=None, keepdims=np._NoValue, initial=np._NoValue,\n           where=np._NoValue):\n    \"\"\"\n    Return the maximum of an array or maximum along an axis, ignoring any NaNs.\n    \"\"\"\n    kwargs = {}\n    if initial is not np._NoValue:\n        kwargs['initial'] = initial\n    if where is not np._NoValue:\n        kwargs['where'] = where\n    if type(a) is not mu.ndarray:\n        try:\n            nanmax = a.nanmax\n        except AttributeError:\n            pass\n        else:\n            return nanmax(axis=axis, out=out, keepdims=keepdims, **kwargs)\n    return _nanextremum(np.max, a, axis, out, keepdims, initial, where)"
    },
    {
      "name": "numpy.percentile",
      "category": "Order statistics",
      "description": "Compute the q-th percentile of the data along the specified axis",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.percentile.html",
      "doc": "numpy.percentile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=False, *, weights=None, interpolation=None)\n\nCompute the q-th percentile of the data along the specified axis.\n\nReturns the q-th percentile(s) of the array elements.\n\nParameters\n----------\na : array_like of real numbers\n    Input array or object that can be converted to an array.\nq : array_like of float\n    Percentile or sequence of percentiles to compute, which must be between 0 and 100 inclusive.\naxis : {int, tuple of int, None}, optional\n    Axis or axes along which the percentiles are computed. The default is to compute the percentile(s) along a flattened version of the array.\nout : ndarray, optional\n    Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output.\noverwrite_input : bool, optional\n    If True, then allow the input array a to be modified by intermediate calculations, to save memory.\nmethod : str, optional\n    This parameter specifies the method to use for estimating the percentile. Default is 'linear'.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\nweights : array_like, optional\n    An array of weights associated with the values in a.\ninterpolation : str, optional\n    Deprecated name for the method keyword argument.\n\nReturns\n-------\npercentile : scalar or ndarray\n    If q is a single percentile and axis=None, then the result is a scalar. Otherwise, an array is returned.",
      "code": "# Implementation in numpy/lib/_function_base_impl.py\n@array_function_dispatch(_percentile_dispatcher)\ndef percentile(a,\n               q,\n               axis=None,\n               out=None,\n               overwrite_input=False,\n               method=\"linear\",\n               keepdims=False,\n               *,\n               weights=None,\n               interpolation=None):\n    \"\"\"\n    Compute the q-th percentile of the data along the specified axis.\n    \"\"\"\n    if interpolation is not None:\n        _raise_warning(interpolation, method)\n    \n    q = np.asanyarray(q)\n    if not _quantile_is_valid(q):\n        raise ValueError(\"Percentiles must be in the range [0, 100]\")\n    q = q / 100\n    \n    a = np.asanyarray(a)\n    if a.dtype.char in \"SUV\":  # strings/unicode/void\n        raise TypeError(\"a must be an array of numerical dtype\")\n    \n    return _quantile(a, q, axis, out, overwrite_input, method, keepdims,\n                     weights)"
    },
    {
      "name": "numpy.nanpercentile",
      "category": "Order statistics",
      "description": "Compute the q-th percentile of the data along the specified axis, ignoring nan values",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.nanpercentile.html",
      "doc": "numpy.nanpercentile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=False, *, weights=None, interpolation=None)\n\nCompute the q-th percentile of the data along the specified axis, ignoring nan values.\n\nReturns the q-th percentile(s) of the array elements.\n\nParameters\n----------\na : array_like\n    Input array or object that can be converted to an array, containing nan values to be ignored.\nq : array_like of float\n    Percentile or sequence of percentiles to compute, which must be between 0 and 100 inclusive.\naxis : {int, tuple of int, None}, optional\n    Axis or axes along which the percentiles are computed.\nout : ndarray, optional\n    Alternative output array in which to place the result.\noverwrite_input : bool, optional\n    If True, then allow the input array a to be modified by intermediate calculations.\nmethod : str, optional\n    Method to use for estimating the percentile.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\nweights : array_like, optional\n    An array of weights associated with the values in a.\ninterpolation : str, optional\n    Deprecated name for the method keyword argument.\n\nReturns\n-------\npercentile : scalar or ndarray\n    If q is a single percentile and axis=None, then the result is a scalar. Otherwise, an array is returned.",
      "code": "# Implementation in numpy/lib/_nanfunctions_impl.py\n@array_function_dispatch(_nanpercentile_dispatcher)\ndef nanpercentile(a,\n                  q,\n                  axis=None,\n                  out=None,\n                  overwrite_input=False,\n                  method=\"linear\",\n                  keepdims=np._NoValue,\n                  *,\n                  weights=None,\n                  interpolation=None):\n    \"\"\"\n    Compute the q-th percentile of the data along the specified axis,\n    ignoring nan values.\n    \"\"\"\n    if interpolation is not None:\n        _raise_warning(interpolation, method)\n    \n    a = np.asanyarray(a)\n    if a.dtype.char in \"SUV\":  # strings/unicode/void\n        raise TypeError(\"a must be an array of numerical dtype\")\n    \n    q = np.asanyarray(q)\n    if not _quantile_is_valid(q):\n        raise ValueError(\"Percentiles must be in the range [0, 100]\")\n    q = q / 100.0\n    \n    return _nanquantile(a, q, axis, out, overwrite_input, method, keepdims,\n                        weights)"
    },
    {
      "name": "numpy.quantile",
      "category": "Order statistics",
      "description": "Compute the q-th quantile of the data along the specified axis",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.quantile.html",
      "doc": "numpy.quantile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=False, *, weights=None, interpolation=None)\n\nCompute the q-th quantile of the data along the specified axis.\n\nParameters\n----------\na : array_like of real numbers\n    Input array or object that can be converted to an array.\nq : array_like of float\n    Quantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive.\naxis : {int, tuple of int, None}, optional\n    Axis or axes along which the quantiles are computed.\nout : ndarray, optional\n    Alternative output array in which to place the result.\noverwrite_input : bool, optional\n    If True, then allow the input array a to be modified by intermediate calculations.\nmethod : str, optional\n    This parameter specifies the method to use for estimating the quantile.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\nweights : array_like, optional\n    An array of weights associated with the values in a.\ninterpolation : str, optional\n    Deprecated name for the method keyword argument.\n\nReturns\n-------\nquantile : scalar or ndarray\n    If q is a single quantile and axis=None, then the result is a scalar.",
      "code": "# Implementation in numpy/lib/_function_base_impl.py\n@array_function_dispatch(_quantile_dispatcher)\ndef quantile(a,\n             q,\n             axis=None,\n             out=None,\n             overwrite_input=False,\n             method=\"linear\",\n             keepdims=False,\n             *,\n             weights=None,\n             interpolation=None):\n    \"\"\"\n    Compute the q-th quantile of the data along the specified axis.\n    \"\"\"\n    if interpolation is not None:\n        _raise_warning(interpolation, method)\n    \n    a = np.asanyarray(a)\n    if a.dtype.char in \"SUV\":  # strings/unicode/void\n        raise TypeError(\"a must be an array of numerical dtype\")\n    \n    q = np.asanyarray(q)\n    if not _quantile_is_valid(q):\n        raise ValueError(\"Quantiles must be in the range [0, 1]\")\n    \n    return _quantile(a, q, axis, out, overwrite_input, method, keepdims,\n                     weights)"
    },
    {
      "name": "numpy.nanquantile",
      "category": "Order statistics",
      "description": "Compute the q-th quantile of the data along the specified axis, ignoring nan values",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.nanquantile.html",
      "doc": "numpy.nanquantile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=False, *, weights=None, interpolation=None)\n\nCompute the q-th quantile of the data along the specified axis, ignoring nan values.\n\nReturns the q-th quantile(s) of the array elements.\n\nParameters\n----------\na : array_like\n    Input array or object that can be converted to an array, containing nan values to be ignored.\nq : array_like of float\n    Quantile or sequence of quantiles to compute, which must be between 0 and 1 inclusive.\naxis : {int, tuple of int, None}, optional\n    Axis or axes along which the quantiles are computed.\nout : ndarray, optional\n    Alternative output array in which to place the result.\noverwrite_input : bool, optional\n    If True, then allow the input array a to be modified by intermediate calculations.\nmethod : str, optional\n    Method to use for estimating the quantile.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\nweights : array_like, optional\n    An array of weights associated with the values in a.\ninterpolation : str, optional\n    Deprecated name for the method keyword argument.\n\nReturns\n-------\nquantile : scalar or ndarray\n    If q is a single quantile and axis=None, then the result is a scalar.",
      "code": "# Implementation in numpy/lib/_nanfunctions_impl.py\n@array_function_dispatch(_nanquantile_dispatcher)\ndef nanquantile(a,\n                q,\n                axis=None,\n                out=None,\n                overwrite_input=False,\n                method=\"linear\",\n                keepdims=np._NoValue,\n                *,\n                weights=None,\n                interpolation=None):\n    \"\"\"\n    Compute the q-th quantile of the data along the specified axis,\n    ignoring nan values.\n    \"\"\"\n    if interpolation is not None:\n        _raise_warning(interpolation, method)\n    \n    a = np.asanyarray(a)\n    if a.dtype.char in \"SUV\":  # strings/unicode/void\n        raise TypeError(\"a must be an array of numerical dtype\")\n    \n    q = np.asanyarray(q)\n    if not _quantile_is_valid(q):\n        raise ValueError(\"Quantiles must be in the range [0, 1]\")\n    \n    return _nanquantile(a, q, axis, out, overwrite_input, method, keepdims,\n                        weights)"
    },
    {
      "name": "numpy.mean",
      "category": "Averages and variances",
      "description": "Compute the arithmetic mean along the specified axis",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.mean.html",
      "doc": "numpy.mean(a, axis=None, dtype=None, out=None, keepdims=<no value>, *, where=<no value>)\n\nCompute the arithmetic mean along the specified axis.\n\nReturns the average of the array elements. The average is taken over the flattened array by default, otherwise over the specified axis. float64 intermediate and return values are used for integer inputs.\n\nParameters\n----------\na : array_like\n    Array containing numbers whose mean is desired. If a is not an array, a conversion is attempted.\naxis : None or int or tuple of ints, optional\n    Axis or axes along which the means are computed. The default is to compute the mean of the flattened array.\ndtype : data-type, optional\n    Type to use in computing the mean. For integer inputs, the default is float64; for floating point inputs, it is the same as the input dtype.\nout : ndarray, optional\n    Alternate output array in which to place the result. The default is None.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\nwhere : array_like of bool, optional\n    Elements to include in the mean.\n\nReturns\n-------\nm : ndarray, see dtype parameter above\n    If out=None, returns a new array containing the mean values, otherwise a reference to the output array is returned.\n\nNotes\n-----\nThe arithmetic mean is the sum of the elements along the axis divided by the number of elements.\n\nNote that for floating-point input, the mean is computed using the same precision the input has. Depending on the input data, this can cause the results to be inaccurate, especially for float32. Specifying a higher-precision accumulator using the dtype keyword can alleviate this issue.",
      "code": "# C implementation for performance\n# Compute the arithmetic mean along the specified axis\n#\n# This function is implemented in C as part of NumPy's core multiarray module.\n# The C implementation provides:\n# - Optimized memory access patterns\n# - Efficient array manipulation\n# - Low-level control over data layout\n# - Integration with NumPy's array object internals\n#\n# Source: # C implementation in numpy/_core/src/multiarray/calculation.c\n# Python wrapper:\n@array_function_dispatch(_mean_dispatcher)\ndef mean(a, axis=None, dtype=None, out=None, keepdims=np._NoValue, *,\n         where=np._NoValue):\n    \"\"\"\n    Compute the arithmetic mean along the specified axis.\n    \"\"\"\n    kwargs = {}\n    if keepdims is not np._NoValue:\n        kwargs['keepdims'] = keepdims\n    if where is not np._NoValue:\n        kwargs['where'] = where\n    if type(a) is not mu.ndarray:\n        try:\n            mean = a.mean\n        except AttributeError:\n            pass\n        else:\n            return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n    \n    return _methods._mean(a, axis=axis, dtype=dtype, out=out, **kwargs)"
    },
    {
      "name": "numpy.average",
      "category": "Averages and variances",
      "description": "Compute the weighted average along the specified axis",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.average.html",
      "doc": "numpy.average(a, axis=None, weights=None, returned=False, *, keepdims=<no value>)\n\nCompute the weighted average along the specified axis.\n\nParameters\n----------\na : array_like\n    Array containing data to be averaged. If a is not an array, a conversion is attempted.\naxis : None or int or tuple of ints, optional\n    Axis or axes along which to average a. The default, axis=None, will average over all of the elements of the input array.\nweights : array_like, optional\n    An array of weights associated with the values in a. Each value in a contributes to the average according to its associated weight.\nreturned : bool, optional\n    Default is False. If True, the tuple (average, sum_of_weights) is returned, otherwise only the average is returned.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\n\nReturns\n-------\nretval, [sum_of_weights] : array_type or double\n    Return the average along the specified axis. When returned is True, return a tuple with the average as the first element and the sum of the weights as the second element.\n\nRaises\n------\nZeroDivisionError\n    When all weights along axis are zero.\nTypeError\n    When the length of 1D weights is not the same as the shape of a along axis.",
      "code": "# Implementation in numpy/lib/_function_base_impl.py\n@array_function_dispatch(_average_dispatcher)\ndef average(a, axis=None, weights=None, returned=False, *,\n            keepdims=np._NoValue):\n    \"\"\"\n    Compute the weighted average along the specified axis.\n    \"\"\"\n    a = np.asanyarray(a)\n    \n    if keepdims is np._NoValue:\n        keepdims_kw = {}\n    else:\n        keepdims_kw = {'keepdims': keepdims}\n    \n    if weights is None:\n        avg = a.mean(axis, **keepdims_kw)\n        avg_as_array = np.asanyarray(avg)\n        scl = avg_as_array.dtype.type(a.size/avg_as_array.size)\n    else:\n        wgt = np.asanyarray(weights)\n        \n        if a.shape != wgt.shape:\n            if axis is None:\n                raise TypeError(\n                    \"Axis must be specified when shapes of a and weights differ.\")\n            if wgt.ndim != 1:\n                raise TypeError(\n                    \"1D weights expected when shapes of a and weights differ.\")\n            if wgt.shape[0] != a.shape[axis]:\n                raise ValueError(\n                    \"Length of weights not compatible with specified axis.\")\n            \n            # setup wgt to broadcast along axis\n            wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape, subok=True)\n            wgt = np.moveaxis(wgt, -1, axis)\n        \n        scl = wgt.sum(axis=axis, **keepdims_kw)\n        if np.any(scl == 0.0):\n            raise ZeroDivisionError(\n                \"Weights sum to zero, can't be normalized\")\n        \n        avg = np.multiply(a, wgt,\n                          dtype=result_type(a.dtype, wgt.dtype, float)).sum(\n                              axis, **keepdims_kw) / scl\n    \n    if returned:\n        if scl.shape != avg.shape:\n            scl = np.broadcast_to(scl, avg.shape).copy()\n        return avg, scl\n    else:\n        return avg"
    },
    {
      "name": "numpy.median",
      "category": "Averages and variances",
      "description": "Compute the median along the specified axis",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.median.html",
      "doc": "numpy.median(a, axis=None, out=None, overwrite_input=False, keepdims=False)\n\nCompute the median along the specified axis.\n\nReturns the median of the array elements.\n\nParameters\n----------\na : array_like\n    Input array or object that can be converted to an array.\naxis : {int, sequence of int, None}, optional\n    Axis or axes along which the medians are computed. The default is to compute the median along a flattened version of the array.\nout : ndarray, optional\n    Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output.\noverwrite_input : bool, optional\n    If True, then allow use of memory of input array a for calculations. The input array will be modified by the call to median.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\n\nReturns\n-------\nmedian : ndarray\n    A new array holding the result. If the input contains integers or floats smaller than float64, then the output data-type is np.float64. Otherwise, the data-type of the output is the same as that of the input.\n\nNotes\n-----\nGiven a vector V of length N, the median of V is the middle value of a sorted copy of V, V_sorted - i.e., V_sorted[(N-1)/2], when N is odd, and the average of the two middle values of V_sorted when N is even.",
      "code": "# Implementation in numpy/lib/_function_base_impl.py\n@array_function_dispatch(_median_dispatcher)\ndef median(a, axis=None, out=None, overwrite_input=False, keepdims=False):\n    \"\"\"\n    Compute the median along the specified axis.\n    \"\"\"\n    return _ureduce(a, func=_median, keepdims=keepdims, axis=axis, out=out,\n                    overwrite_input=overwrite_input)\n\ndef _median(a, axis=None, out=None, overwrite_input=False):\n    # can't be reasonably be implemented in terms of percentile as we have\n    # to call mean to not break astropy\n    a = np.asanyarray(a)\n    \n    # Set the partition indexes\n    if axis is None:\n        sz = a.size\n    else:\n        sz = a.shape[axis]\n    if sz % 2 == 0:\n        szh = sz // 2\n        kth = [szh - 1, szh]\n    else:\n        kth = [(sz - 1) // 2]\n    \n    # Check if the array contains any nan's\n    if np.issubdtype(a.dtype, np.inexact):\n        kth.append(-1)\n    \n    if overwrite_input:\n        if axis is None:\n            part = a.ravel()\n            part.partition(kth)\n        else:\n            a.partition(kth, axis=axis)\n            part = a\n    else:\n        part = partition(a, kth, axis=axis)\n    \n    if part.shape == ():\n        # make 0-D arrays work\n        return part.item()\n    if axis is None:\n        axis = 0\n    \n    indexer = [slice(None)] * part.ndim\n    index = part.shape[axis] // 2\n    if part.shape[axis] % 2 == 1:\n        # index with slice to allow mean (below) to work\n        indexer[axis] = slice(index, index+1)\n    else:\n        indexer[axis] = slice(index-1, index+1)\n    indexer = tuple(indexer)\n    \n    # Check if the array contains any nan's\n    if np.issubdtype(a.dtype, np.inexact) and sz > 0:\n        # warn and return nans like mean would\n        rout = mean(part[indexer], axis=axis, out=out)\n        return np.lib._utils._median_nancheck(part, rout, axis)\n    else:\n        # if there are no nans\n        # Use mean in odd and even case to coerce data type,\n        # using out array if needed.\n        rout = mean(part[indexer], axis=axis, out=out)\n        return rout"
    },
    {
      "name": "numpy.nanmean",
      "category": "Averages and variances",
      "description": "Compute the arithmetic mean along the specified axis, ignoring NaNs",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.nanmean.html",
      "doc": "numpy.nanmean(a, axis=None, dtype=None, out=None, keepdims=<no value>, *, where=<no value>)\n\nCompute the arithmetic mean along the specified axis, ignoring NaNs.\n\nReturns the average of the array elements. The average is taken over the flattened array by default, otherwise over the specified axis. float64 intermediate and return values are used for integer inputs.\n\nFor all-NaN slices, NaN is returned and a RuntimeWarning is raised.\n\nParameters\n----------\na : array_like\n    Array containing numbers whose mean is desired. If a is not an array, a conversion is attempted.\naxis : {int, tuple of int, None}, optional\n    Axis or axes along which the means are computed. The default is to compute the mean of the flattened array.\ndtype : data-type, optional\n    Type to use in computing the mean. For integer inputs, the default is float64; for inexact inputs, it is the same as the input dtype.\nout : ndarray, optional\n    Alternate output array in which to place the result. The default is None.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\nwhere : array_like of bool, optional\n    Elements to include in the mean.\n\nReturns\n-------\nm : ndarray, see dtype parameter above\n    If out=None, returns a new array containing the mean values, otherwise a reference to the output array is returned. Nan is returned for slices that contain only NaNs.",
      "code": "# Implementation in numpy/lib/_nanfunctions_impl.py\n@array_function_dispatch(_nanmean_dispatcher)\ndef nanmean(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,\n            *, where=np._NoValue):\n    \"\"\"\n    Compute the arithmetic mean along the specified axis, ignoring NaNs.\n    \"\"\"\n    arr, mask = _replace_nan(a, 0)\n    if mask is None:\n        return np.mean(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,\n                       where=where)\n    \n    if dtype is not None:\n        dtype = np.dtype(dtype)\n    if dtype is not None and not issubclass(dtype.type, np.inexact):\n        raise TypeError(\"If a is inexact, then dtype must be inexact\")\n    if out is not None and not issubclass(out.dtype.type, np.inexact):\n        raise TypeError(\"If a is inexact, then out must be inexact\")\n    \n    cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=keepdims,\n                 where=where)\n    tot = np.sum(arr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,\n                 where=where)\n    avg = _divide_by_count(tot, cnt, out=out)\n    \n    isbad = (cnt == 0)\n    if isbad.any():\n        warnings.warn(\"Mean of empty slice\", RuntimeWarning, stacklevel=2)\n        # NaN is the only possible bad value, so no further\n        # action is needed to handle bad results.\n    return avg"
    },
    {
      "name": "numpy.nanmedian",
      "category": "Averages and variances",
      "description": "Compute the median along the specified axis, ignoring NaNs",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.nanmedian.html",
      "doc": "numpy.nanmedian(a, axis=None, out=None, overwrite_input=False, keepdims=False)\n\nCompute the median along the specified axis, while ignoring NaNs.\n\nReturns the median of the array elements.\n\nParameters\n----------\na : array_like\n    Input array or object that can be converted to an array.\naxis : {int, sequence of int, None}, optional\n    Axis or axes along which the medians are computed. The default is to compute the median along a flattened version of the array.\nout : ndarray, optional\n    Alternative output array in which to place the result. It must have the same shape and buffer length as the expected output.\noverwrite_input : bool, optional\n    If True, then allow use of memory of input array a for calculations. The input array will be modified by the call to median.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\n\nReturns\n-------\nmedian : ndarray\n    A new array holding the result. If the input contains integers or floats smaller than float64, then the output data-type is np.float64. Otherwise, the data-type of the output is the same as that of the input.\n\nNotes\n-----\nGiven a vector V of length N, the median of V is the middle value of a sorted copy of V, V_sorted - i.e., V_sorted[(N-1)/2], when N is odd, and the average of the two middle values of V_sorted when N is even.",
      "code": "# Implementation in numpy/lib/_nanfunctions_impl.py\n@array_function_dispatch(_nanmedian_dispatcher)\ndef nanmedian(a, axis=None, out=None, overwrite_input=False, keepdims=False):\n    \"\"\"\n    Compute the median along the specified axis, while ignoring NaNs.\n    \"\"\"\n    a = np.asanyarray(a)\n    # apply_along_axis in _nanmedian doesn't handle empty arrays well,\n    # so deal them upfront\n    if a.size == 0:\n        return np.nanmean(a, axis, out=out, keepdims=keepdims)\n    \n    return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,\n                                  axis=axis, out=out,\n                                  overwrite_input=overwrite_input)\n\ndef _nanmedian(a, axis=None, out=None, overwrite_input=False):\n    \"\"\"\n    Private function that doesn't support extended axis or keepdims.\n    These extended features are handled by _ureduce.\n    \"\"\"\n    if axis is None or a.ndim == 1:\n        part = a.ravel()\n        if out is None:\n            return _nanmedian1d(part, overwrite_input)\n        else:\n            out[...] = _nanmedian1d(part, overwrite_input)\n            return out\n    else:\n        # for small medians use sort + indexing which is still faster than\n        # apply_along_axis\n        # benchmarked with shuffled (50, 50, x) median axis=2\n        if a.shape[axis] < 600:\n            return _nanmedian_small(a, axis, out, overwrite_input)\n        result = np.apply_along_axis(_nanmedian1d, axis, a, overwrite_input)\n        if out is not None:\n            out[...] = result\n        return result"
    },
    {
      "name": "numpy.var",
      "category": "Averages and variances",
      "description": "Compute the variance along the specified axis",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.var.html",
      "doc": "numpy.var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>, *, where=<no value>)\n\nCompute the variance along the specified axis.\n\nReturns the variance of the array elements, a measure of the spread of a distribution. The variance is computed for the flattened array by default, otherwise over the specified axis.\n\nParameters\n----------\na : array_like\n    Array containing numbers whose variance is desired. If a is not an array, a conversion is attempted.\naxis : None or int or tuple of ints, optional\n    Axis or axes along which the variance is computed. The default is to compute the variance of the flattened array.\ndtype : data-type, optional\n    Type to use in computing the variance. For arrays of integer type the default is float64; for arrays of float types it is the same as the array type.\nout : ndarray, optional\n    Alternate output array in which to place the result. It must have the same shape as the expected output.\nddof : int, optional\n    \"Delta Degrees of Freedom\": the divisor used in the calculation is N - ddof, where N represents the number of elements. By default ddof is zero.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\nwhere : array_like of bool, optional\n    Elements to include in the variance.\n\nReturns\n-------\nvariance : ndarray, see dtype parameter above\n    If out=None, returns a new array containing the variance; otherwise, a reference to the output array is returned.\n\nNotes\n-----\nThe variance is the average of the squared deviations from the mean, i.e., var = mean(x - x.mean())**2.\n\nThe mean is typically calculated as x.sum() / N, where N = len(x). If, however, ddof is specified, the divisor N - ddof is used instead. In standard statistical practice, ddof=1 provides an unbiased estimator of the variance of a hypothetical infinite population. ddof=0 provides a maximum likelihood estimate of the variance for normally distributed variables.",
      "code": "# C implementation for performance\n# Compute the variance along the specified axis\n#\n# This function is implemented in C as part of NumPy's core multiarray module.\n# The C implementation provides:\n# - Optimized memory access patterns\n# - Efficient array manipulation\n# - Low-level control over data layout\n# - Integration with NumPy's array object internals\n#\n# Source: # C implementation in numpy/_core/src/multiarray/calculation.c\n# Python wrapper:\n@array_function_dispatch(_var_dispatcher)\ndef var(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue,\n        *, where=np._NoValue):\n    \"\"\"\n    Compute the variance along the specified axis.\n    \"\"\"\n    kwargs = {}\n    if keepdims is not np._NoValue:\n        kwargs['keepdims'] = keepdims\n    if where is not np._NoValue:\n        kwargs['where'] = where\n    \n    if type(a) is not mu.ndarray:\n        try:\n            var = a.var\n        except AttributeError:\n            pass\n        else:\n            return var(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n    \n    return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n                         **kwargs)"
    },
    {
      "name": "numpy.std",
      "category": "Averages and variances",
      "description": "Compute the standard deviation along the specified axis",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.std.html",
      "doc": "numpy.std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>, *, where=<no value>)\n\nCompute the standard deviation along the specified axis.\n\nReturns the standard deviation, a measure of the spread of a distribution, of the array elements. The standard deviation is computed for the flattened array by default, otherwise over the specified axis.\n\nParameters\n----------\na : array_like\n    Calculate the standard deviation of these values.\naxis : None or int or tuple of ints, optional\n    Axis or axes along which the standard deviation is computed. The default is to compute the standard deviation of the flattened array.\ndtype : dtype, optional\n    Type to use in computing the standard deviation. For arrays of integer type the default is float64, for arrays of float types it is the same as the array type.\nout : ndarray, optional\n    Alternative output array in which to place the result. It must have the same shape as the expected output.\nddof : int, optional\n    Means Delta Degrees of Freedom. The divisor used in calculations is N - ddof, where N represents the number of elements. By default ddof is zero.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\nwhere : array_like of bool, optional\n    Elements to include in the standard deviation.\n\nReturns\n-------\nstandard_deviation : ndarray, see dtype parameter above.\n    If out is None, return a new array containing the standard deviation, otherwise return a reference to the output array.\n\nNotes\n-----\nThe standard deviation is the square root of the average of the squared deviations from the mean, i.e., std = sqrt(mean(x - x.mean())**2).\n\nThe average squared deviation is typically calculated as x.sum() / N, where N = len(x). If, however, ddof is specified, the divisor N - ddof is used instead. In standard statistical practice, ddof=1 provides an unbiased estimator of the variance of a hypothetical infinite population. ddof=0 provides a maximum likelihood estimate of the variance for normally distributed variables. The standard deviation computed in this function is the square root of the estimated variance, so even with ddof=1, it will not be an unbiased estimate of the standard deviation per se.",
      "code": "# C implementation for performance\n# Compute the standard deviation along the specified axis\n#\n# This function is implemented in C as part of NumPy's core multiarray module.\n# The C implementation provides:\n# - Optimized memory access patterns\n# - Efficient array manipulation\n# - Low-level control over data layout\n# - Integration with NumPy's array object internals\n#\n# Source: # C implementation in numpy/_core/src/multiarray/calculation.c\n# Python wrapper:\n@array_function_dispatch(_std_dispatcher)\ndef std(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue,\n        *, where=np._NoValue):\n    \"\"\"\n    Compute the standard deviation along the specified axis.\n    \"\"\"\n    kwargs = {}\n    if keepdims is not np._NoValue:\n        kwargs['keepdims'] = keepdims\n    if where is not np._NoValue:\n        kwargs['where'] = where\n    \n    if type(a) is not mu.ndarray:\n        try:\n            std = a.std\n        except AttributeError:\n            pass\n        else:\n            return std(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n    \n    return _methods._std(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n                         **kwargs)"
    },
    {
      "name": "numpy.nanvar",
      "category": "Averages and variances",
      "description": "Compute the variance along the specified axis, ignoring NaNs",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.nanvar.html",
      "doc": "numpy.nanvar(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>, *, where=<no value>)\n\nCompute the variance along the specified axis, while ignoring NaNs.\n\nReturns the variance of the array elements, a measure of the spread of a distribution. The variance is computed for the flattened array by default, otherwise over the specified axis.\n\nFor all-NaN slices, NaN is returned and a RuntimeWarning is raised.\n\nParameters\n----------\na : array_like\n    Array containing numbers whose variance is desired. If a is not an array, a conversion is attempted.\naxis : {int, tuple of int, None}, optional\n    Axis or axes along which the variance is computed. The default is to compute the variance of the flattened array.\ndtype : data-type, optional\n    Type to use in computing the variance. For arrays of integer type the default is float64; for arrays of float types it is the same as the array type.\nout : ndarray, optional\n    Alternate output array in which to place the result. It must have the same shape as the expected output.\nddof : int, optional\n    \"Delta Degrees of Freedom\": the divisor used in the calculation is N - ddof, where N represents the number of non-NaN elements. By default ddof is zero.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\nwhere : array_like of bool, optional\n    Elements to include in the variance.\n\nReturns\n-------\nvariance : ndarray, see dtype parameter above\n    If out is None, returns a new array containing the variance; otherwise, a reference to the output array is returned. If ddof is >= the number of non-NaN elements in a slice or the slice contains only NaNs, then the result for that slice is NaN.",
      "code": "# Implementation in numpy/lib/_nanfunctions_impl.py\n@array_function_dispatch(_nanvar_dispatcher)\ndef nanvar(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue,\n           *, where=np._NoValue):\n    \"\"\"\n    Compute the variance along the specified axis, while ignoring NaNs.\n    \"\"\"\n    arr, mask = _replace_nan(a, 0)\n    if mask is None:\n        return np.var(arr, axis=axis, dtype=dtype, out=out, ddof=ddof,\n                      keepdims=keepdims, where=where)\n    \n    if dtype is not None:\n        dtype = np.dtype(dtype)\n    if dtype is not None and not issubclass(dtype.type, np.inexact):\n        raise TypeError(\"If a is inexact, then dtype must be inexact\")\n    if out is not None and not issubclass(out.dtype.type, np.inexact):\n        raise TypeError(\"If a is inexact, then out must be inexact\")\n    \n    # Compute mean\n    cnt = np.sum(~mask, axis=axis, dtype=np.intp, keepdims=True,\n                 where=where)\n    avg = np.sum(arr, axis=axis, dtype=dtype, keepdims=True, where=where)\n    avg = _divide_by_count(avg, cnt)\n    \n    # Compute squared deviations\n    np.subtract(arr, avg, out=arr, where=~mask)\n    arr = _copyto(arr, 0, mask)\n    if issubclass(arr.dtype.type, np.complexfloating):\n        sqr = np.multiply(arr, arr.conj(), out=arr).real\n    else:\n        sqr = np.multiply(arr, arr, out=arr)\n    \n    # Compute variance\n    var = np.sum(sqr, axis=axis, dtype=dtype, out=out, keepdims=keepdims,\n                 where=where)\n    \n    if not keepdims and cnt.ndim != var.ndim:\n        cnt = cnt.squeeze(axis)\n    dof = cnt - ddof\n    var = _divide_by_count(var, dof)\n    \n    isbad = (dof <= 0)\n    if isbad.any():\n        warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning,\n                      stacklevel=2)\n        # NaN, inf, or negative numbers are all possible bad\n        # values, so explicitly replace them with NaN.\n        var = _copyto(var, np.nan, isbad)\n    \n    return var"
    },
    {
      "name": "numpy.nanstd",
      "category": "Averages and variances",
      "description": "Compute the standard deviation along the specified axis, ignoring NaNs",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.nanstd.html",
      "doc": "numpy.nanstd(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>, *, where=<no value>)\n\nCompute the standard deviation along the specified axis, while ignoring NaNs.\n\nReturns the standard deviation, a measure of the spread of a distribution, of the non-NaN array elements. The standard deviation is computed for the flattened array by default, otherwise over the specified axis.\n\nFor all-NaN slices, NaN is returned and a RuntimeWarning is raised.\n\nParameters\n----------\na : array_like\n    Calculate the standard deviation of the non-NaN values.\naxis : {int, tuple of int, None}, optional\n    Axis or axes along which the standard deviation is computed. The default is to compute the standard deviation of the flattened array.\ndtype : dtype, optional\n    Type to use in computing the standard deviation. For arrays of integer type the default is float64, for arrays of float types it is the same as the array type.\nout : ndarray, optional\n    Alternative output array in which to place the result. It must have the same shape as the expected output.\nddof : int, optional\n    Means Delta Degrees of Freedom. The divisor used in calculations is N - ddof, where N represents the number of non-NaN elements. By default ddof is zero.\nkeepdims : bool, optional\n    If this is set to True, the axes which are reduced are left in the result as dimensions with size one.\nwhere : array_like of bool, optional\n    Elements to include in the standard deviation.\n\nReturns\n-------\nstandard_deviation : ndarray, see dtype parameter above.\n    If out is None, return a new array containing the standard deviation, otherwise return a reference to the output array. If ddof is >= the number of non-NaN elements in a slice or the slice contains only NaNs, then the result for that slice is NaN.",
      "code": "# Implementation in numpy/lib/_nanfunctions_impl.py\n@array_function_dispatch(_nanstd_dispatcher)\ndef nanstd(a, axis=None, dtype=None, out=None, ddof=0, keepdims=np._NoValue,\n           *, where=np._NoValue):\n    \"\"\"\n    Compute the standard deviation along the specified axis, while ignoring NaNs.\n    \"\"\"\n    var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n                 keepdims=keepdims, where=where)\n    if isinstance(var, np.ndarray):\n        std = np.sqrt(var, out=var)\n    elif hasattr(var, 'dtype'):\n        std = var.dtype.type(np.sqrt(var))\n    else:\n        std = np.sqrt(var)\n    return std"
    },
    {
      "name": "numpy.corrcoef",
      "category": "Correlating",
      "description": "Return Pearson product-moment correlation coefficients",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html",
      "doc": "numpy.corrcoef(x, y=None, rowvar=True, bias=<no value>, ddof=<no value>, *, dtype=None)\n\nReturn Pearson product-moment correlation coefficients.\n\nPlease refer to the documentation for cov for more detail. The relationship between the correlation coefficient matrix, R, and the covariance matrix, C, is\n\nR_{ij} = C_{ij} / sqrt(C_{ii} * C_{jj})\n\nThe values of R are between -1 and 1, inclusive.\n\nParameters\n----------\nx : array_like\n    A 1-D or 2-D array containing multiple variables and observations. Each row of x represents a variable, and each column a single observation of all those variables. Also see rowvar below.\ny : array_like, optional\n    An additional set of variables and observations. y has the same shape as x.\nrowvar : bool, optional\n    If rowvar is True (default), then each row represents a variable, with observations in the columns. Otherwise, the relationship is transposed: each column represents a variable, while the rows contain observations.\nbias : _NoValue, optional\n    Has no effect, do not use.\nddof : _NoValue, optional\n    Has no effect, do not use.\ndtype : data-type, optional\n    Data-type of the result. By default, the return data-type will have at least numpy.float64 precision.\n\nReturns\n-------\nR : ndarray\n    The correlation coefficient matrix of the variables.\n\nNotes\n-----\nDue to floating point rounding the resulting array may not be Hermitian, the diagonal elements may not be 1, and the elements may not satisfy the inequality abs(a) <= 1. The real and imaginary parts are clipped to the interval [-1, 1] in an attempt to improve on that situation but is not much help in the complex case.",
      "code": "# Implementation in numpy/lib/_function_base_impl.py\n@array_function_dispatch(_corrcoef_dispatcher)\ndef corrcoef(x, y=None, rowvar=True, bias=np._NoValue, ddof=np._NoValue,\n             *, dtype=None):\n    \"\"\"\n    Return Pearson product-moment correlation coefficients.\n    \"\"\"\n    if bias is not np._NoValue or ddof is not np._NoValue:\n        warnings.warn('bias and ddof have no effect and are deprecated',\n                      DeprecationWarning, stacklevel=2)\n    \n    c = cov(x, y, rowvar, dtype=dtype)\n    try:\n        d = diag(c)\n    except ValueError:\n        # scalar covariance\n        # nan if incorrect value (nan, inf, 0), 1 otherwise\n        return c / c\n    \n    stddev = sqrt(d.real)\n    c /= stddev[:, None]\n    c /= stddev[None, :]\n    \n    # Clip to [-1, 1].  This does not guarantee\n    # abs(a[i,j]) <= 1 for complex arrays, but is\n    # the best we can do without excessive work.\n    np.clip(c.real, -1, 1, out=c.real)\n    if np.iscomplexobj(c):\n        np.clip(c.imag, -1, 1, out=c.imag)\n    \n    return c"
    },
    {
      "name": "numpy.cov",
      "category": "Correlating",
      "description": "Estimate a covariance matrix, given data and weights",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.cov.html",
      "doc": "numpy.cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None, aweights=None, *, dtype=None)\n\nEstimate a covariance matrix, given data and weights.\n\nCovariance indicates the level to which two variables vary together. If we examine N-dimensional samples, X = [x_1, x_2, ... x_N]^T, then the covariance matrix element C_{ij} is the covariance of x_i and x_j. The element C_{ii} is the variance of x_i.\n\nParameters\n----------\nm : array_like\n    A 1-D or 2-D array containing multiple variables and observations. Each row of m represents a variable, and each column a single observation of all those variables. Also see rowvar below.\ny : array_like, optional\n    An additional set of variables and observations. y has the same form as that of m.\nrowvar : bool, optional\n    If rowvar is True (default), then each row represents a variable, with observations in the columns. Otherwise, the relationship is transposed: each column represents a variable, while the rows contain observations.\nbias : bool, optional\n    Default normalization (False) is by (N - 1), where N is the number of observations given (unbiased estimate). If bias is True, then normalization is by N.\nddof : int, optional\n    If not None the default value implied by bias is overridden. Note that ddof=1 will return the unbiased estimate, even if both fweights and aweights are specified.\nfweights : array_like, int, optional\n    1-D array of integer frequency weights; the number of times each observation vector should be repeated.\naweights : array_like, optional\n    1-D array of observation vector weights. These relative weights are typically large for observations considered \"important\" and smaller for observations considered less \"important\".\ndtype : data-type, optional\n    Data-type of the result. By default, the return data-type will have at least numpy.float64 precision.\n\nReturns\n-------\nout : ndarray\n    The covariance matrix of the variables.",
      "code": "# Implementation in numpy/lib/_function_base_impl.py\n@array_function_dispatch(_cov_dispatcher)\ndef cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None,\n        aweights=None, *, dtype=None):\n    \"\"\"\n    Estimate a covariance matrix, given data and weights.\n    \"\"\"\n    # Check inputs\n    if ddof is not None and ddof != int(ddof):\n        raise ValueError(\n            \"ddof must be integer\")\n    \n    # Handles complex arrays too\n    m = np.asarray(m)\n    if m.ndim > 2:\n        raise ValueError(\"m has more than 2 dimensions\")\n    \n    if y is not None:\n        y = np.asarray(y)\n        if y.ndim > 2:\n            raise ValueError(\"y has more than 2 dimensions\")\n    \n    if dtype is None:\n        if y is None:\n            dtype = np.result_type(m, np.float64)\n        else:\n            dtype = np.result_type(m, y, np.float64)\n    \n    X = array(m, ndmin=2, dtype=dtype)\n    if not rowvar and X.shape[0] != 1:\n        X = X.T\n    if X.shape[0] == 0:\n        return np.array([]).reshape(0, 0)\n    if y is not None:\n        y = array(y, ndmin=2, dtype=dtype)\n        if not rowvar and y.shape[0] != 1:\n            y = y.T\n        X = np.concatenate((X, y), axis=0)\n    \n    if ddof is None:\n        if bias == 0:\n            ddof = 1\n        else:\n            ddof = 0\n    \n    # Get the product of frequencies and weights\n    w = None\n    if fweights is not None:\n        fweights = np.asarray(fweights, dtype=float)\n        if not np.all(fweights == np.around(fweights)):\n            raise TypeError(\n                \"fweights must be integer\")\n        if fweights.ndim > 1:\n            raise RuntimeError(\n                \"cannot handle multidimensional fweights\")\n        if fweights.shape[0] != X.shape[1]:\n            raise RuntimeError(\n                \"incompatible numbers of samples and fweights\")\n        if any(fweights < 0):\n            raise ValueError(\n                \"fweights cannot be negative\")\n        w = fweights\n    if aweights is not None:\n        aweights = np.asarray(aweights, dtype=float)\n        if aweights.ndim > 1:\n            raise RuntimeError(\n                \"cannot handle multidimensional aweights\")\n        if aweights.shape[0] != X.shape[1]:\n            raise RuntimeError(\n                \"incompatible numbers of samples and aweights\")\n        if any(aweights < 0):\n            raise ValueError(\n                \"aweights cannot be negative\")\n        if w is None:\n            w = aweights\n        else:\n            w *= aweights\n    \n    avg, w_sum = average(X, axis=1, weights=w, returned=True)\n    w_sum = w_sum[0]\n    \n    # Determine the normalization\n    if w is None:\n        fact = X.shape[1] - ddof\n    elif ddof == 0:\n        fact = w_sum\n    elif aweights is None:\n        fact = w_sum - ddof\n    else:\n        fact = w_sum - ddof*sum(w*aweights)/w_sum\n    \n    if fact <= 0:\n        warnings.warn(\"Degrees of freedom <= 0 for slice\",\n                      RuntimeWarning, stacklevel=2)\n        fact = 0.0\n    \n    X -= avg[:, None]\n    if w is None:\n        X_T = X.T\n    else:\n        X_T = (X*w).T\n    c = dot(X, X_T.conj())\n    c *= np.true_divide(1, fact)\n    return c.squeeze()"
    },
    {
      "name": "numpy.correlate",
      "category": "Correlating",
      "description": "Cross-correlation of two 1-dimensional sequences",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.correlate.html",
      "doc": "numpy.correlate(a, v, mode='valid')\n\nCross-correlation of two 1-dimensional sequences.\n\nThis function computes the correlation as generally defined in signal processing texts:\n\nc_k = sum_n a_{n+k} * conj(v_n)\n\nwith a and v sequences being zero-padded where necessary and conj being the complex conjugate.\n\nParameters\n----------\na, v : array_like\n    Input sequences.\nmode : {'valid', 'same', 'full'}, optional\n    Refer to the convolve docstring. Note that the default is 'valid', unlike convolve, which uses 'full'.\n\nReturns\n-------\nout : ndarray\n    Discrete cross-correlation of a and v.\n\nNotes\n-----\nThe definition of correlation above is not unique and sometimes correlation may be defined differently. Another common definition is:\n\nc'_k = sum_n a_n * conj(v_{n+k})\n\nwhich is related to c_k by c'_k = conj(c_{-k}).",
      "code": "# C implementation for performance\n# Cross-correlation of two 1-dimensional sequences\n#\n# This function is implemented in C as part of NumPy's core multiarray module.\n# The C implementation provides:\n# - Optimized memory access patterns\n# - Efficient array manipulation\n# - Low-level control over data layout\n# - Integration with NumPy's array object internals\n#\n# Source: # C implementation in numpy/_core/src/multiarray/multiarraymodule.c\n# Python wrapper:\n@array_function_dispatch(_correlate_dispatcher)\ndef correlate(a, v, mode='valid'):\n    \"\"\"\n    Cross-correlation of two 1-dimensional sequences.\n    \"\"\"\n    a, v = array(a, ndmin=1), array(v, ndmin=1)\n    if len(a) == 0 or len(v) == 0:\n        raise ValueError('a and v must have length at least 1')\n    if a.ndim != 1 or v.ndim != 1:\n        raise ValueError('a and v must be 1-dimensional')\n    \n    try:\n        return multiarray.correlate(a, v, mode)\n    except ValueError:\n        # multiarray.correlate raises ValueError for bad mode,\n        # so we don't need to catch that here\n        raise"
    },
    {
      "name": "numpy.histogram",
      "category": "Histograms",
      "description": "Compute the histogram of a dataset",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.histogram.html",
      "doc": "numpy.histogram(a, bins=10, range=None, density=None, weights=None)\n\nCompute the histogram of a dataset.\n\nParameters\n----------\na : array_like\n    Input data. The histogram is computed over the flattened array.\nbins : int or sequence of scalars or str, optional\n    If bins is an int, it defines the number of equal-width bins in the given range (10, by default). If bins is a sequence, it defines a monotonically increasing array of bin edges, including the rightmost edge, allowing for non-uniform bin widths.\nrange : (float, float), optional\n    The lower and upper range of the bins. If not provided, range is simply (a.min(), a.max()). Values outside the range are ignored.\ndensity : bool, optional\n    If False, the result will contain the number of samples in each bin. If True, the result is the value of the probability density function at the bin, normalized such that the integral over the range is 1.\nweights : array_like, optional\n    An array of weights, of the same shape as a. Each value in a only contributes its associated weight towards the bin count (instead of 1).\n\nReturns\n-------\nhist : array\n    The values of the histogram.\nbin_edges : array of dtype float\n    Return the bin edges (length(hist)+1).",
      "code": "# Implementation in numpy/lib/_histograms_impl.py\n@array_function_dispatch(_histogram_dispatcher)\ndef histogram(a, bins=10, range=None, density=None, weights=None):\n    \"\"\"\n    Compute the histogram of a dataset.\n    \"\"\"\n    a, weights = _ravel_and_check_weights(a, weights)\n    \n    bin_edges, uniform_bins = _get_bin_edges(a, bins, range, weights)\n    \n    # Histogram is an integer or a float array depending on the weights.\n    if weights is None:\n        ntype = np.dtype(np.intp)\n    else:\n        ntype = weights.dtype\n    \n    # We set a block size, as this allows us to iterate over chunks when\n    # computing histograms, to minimize memory usage.\n    BLOCK = 65536\n    \n    # The fast path uses bincount, but that only works for certain types\n    # of weight\n    simple_weights = (\n        weights is None or\n        np.can_cast(weights.dtype, np.double) or\n        np.can_cast(weights.dtype, complex)\n    )\n    \n    if uniform_bins is not None and simple_weights:\n        # Fast algorithm for equal bins\n        # We now convert values of a to bin indices, under the assumption of\n        # equal bin widths (which is valid here).\n        first_edge, last_edge, n_equal_bins = uniform_bins\n        \n        # Initialize empty histogram\n        n = np.zeros(n_equal_bins, ntype)\n        \n        # Pre-compute histogram scaling factor\n        norm_numerator = n_equal_bins\n        norm_denom = _unsigned_subtract(last_edge, first_edge)\n        \n        # We iterate over blocks here for two reasons: the first is that for\n        # large arrays, it is actually faster (for example for a 10^8 array it\n        # is 2x as fast) and it results in a memory footprint 3x lower in the\n        # limit of large arrays.\n        for i in _range(0, len(a), BLOCK):\n            tmp_a = a[i:i+BLOCK]\n            if weights is None:\n                tmp_w = None\n            else:\n                tmp_w = weights[i:i + BLOCK]\n            \n            # Only include values in the right range\n            keep = (tmp_a >= first_edge)\n            keep &= (tmp_a <= last_edge)\n            if not np.logical_and.reduce(keep):\n                tmp_a = tmp_a[keep]\n                if tmp_w is not None:\n                    tmp_w = tmp_w[keep]\n            \n            # Compute bin indices, and for values that lie exactly on\n            # last_edge we need to subtract one\n            f_indices = ((_unsigned_subtract(tmp_a, first_edge) /\n                          norm_denom) * norm_numerator)\n            indices = f_indices.astype(np.intp)\n            indices[indices == n_equal_bins] -= 1\n            \n            # The index computation is not guaranteed to give exactly\n            # consistent results within ~1 ULP of the bin edges.\n            decrement = tmp_a < bin_edges[indices]\n            indices[decrement] -= 1\n            # The last bin includes the right edge. The other bins do not.\n            increment = ((tmp_a >= bin_edges[indices + 1])\n                         & (indices != n_equal_bins - 1))\n            indices[increment] += 1\n            \n            # We now compute the histogram using bincount\n            if ntype.kind == 'c':\n                n.real += np.bincount(indices, weights=tmp_w.real,\n                                      minlength=n_equal_bins)\n                n.imag += np.bincount(indices, weights=tmp_w.imag,\n                                      minlength=n_equal_bins)\n            else:\n                n += np.bincount(indices, weights=tmp_w,\n                                 minlength=n_equal_bins).astype(ntype)\n    else:\n        # Compute via cumulative histogram\n        cum_n = np.zeros(bin_edges.shape, ntype)\n        if weights is None:\n            for i in _range(0, len(a), BLOCK):\n                sa = np.sort(a[i:i+BLOCK])\n                cum_n += _search_sorted_inclusive(sa, bin_edges)\n        else:\n            zero = np.zeros(1, dtype=ntype)\n            for i in _range(0, len(a), BLOCK):\n                tmp_a = a[i:i+BLOCK]\n                tmp_w = weights[i:i+BLOCK]\n                sorting_index = np.argsort(tmp_a)\n                sa = tmp_a[sorting_index]\n                sw = tmp_w[sorting_index]\n                cw = np.concatenate((zero, sw.cumsum()))\n                bin_index = _search_sorted_inclusive(sa, bin_edges)\n                cum_n += cw[bin_index]\n        \n        n = np.diff(cum_n)\n    \n    # density overrides the density keyword argument\n    if density:\n        db = np.array(np.diff(bin_edges), float)\n        return n/db/n.sum(), bin_edges\n    \n    return n, bin_edges"
    },
    {
      "name": "numpy.histogram2d",
      "category": "Histograms",
      "description": "Compute the bi-dimensional histogram of two data samples",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.histogram2d.html",
      "doc": "numpy.histogram2d(x, y, bins=10, range=None, density=None, weights=None)\n\nCompute the bi-dimensional histogram of two data samples.\n\nParameters\n----------\nx : array_like, shape (N,)\n    An array containing the x coordinates of the points to be histogrammed.\ny : array_like, shape (N,)\n    An array containing the y coordinates of the points to be histogrammed.\nbins : int or array_like or [int, int] or [array, array], optional\n    The bin specification:\n    * If int, the number of bins for the two dimensions (nx=ny=bins).\n    * If array_like, the bin edges for the two dimensions (x_edges=y_edges=bins).\n    * If [int, int], the number of bins in each dimension (nx, ny = bins).\n    * If [array, array], the bin edges in each dimension (x_edges, y_edges = bins).\nrange : array_like, shape(2,2), optional\n    The leftmost and rightmost edges of the bins along each dimension (if not specified explicitly in the bins parameters): [[xmin, xmax], [ymin, ymax]].\ndensity : bool, optional\n    If False, the default, returns the number of samples in each bin. If True, returns the probability density function at the bin.\nweights : array_like, shape(N,), optional\n    An array of values w_i weighing each sample (x_i, y_i).\n\nReturns\n-------\nH : ndarray, shape(nx, ny)\n    The bi-dimensional histogram of samples x and y.\nxedges : ndarray, shape(nx+1,)\n    The bin edges along the first dimension.\nyedges : ndarray, shape(ny+1,)\n    The bin edges along the second dimension.",
      "code": "# Implementation in numpy/lib/_twodim_base_impl.py\n@array_function_dispatch(_histogram2d_dispatcher)\ndef histogram2d(x, y, bins=10, range=None, density=None, weights=None):\n    \"\"\"\n    Compute the bi-dimensional histogram of two data samples.\n    \"\"\"\n    from numpy import histogramdd\n    \n    if len(x) != len(y):\n        raise ValueError('x and y must have the same length.')\n    \n    try:\n        N = len(bins)\n    except TypeError:\n        N = 1\n    \n    if N != 1 and N != 2:\n        xedges = yedges = np.asarray(bins)\n        bins = [xedges, yedges]\n    \n    hist, edges = histogramdd([x, y], bins, range, density, weights)\n    return hist, edges[0], edges[1]"
    },
    {
      "name": "numpy.histogramdd",
      "category": "Histograms",
      "description": "Compute the multidimensional histogram of some data",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.histogramdd.html",
      "doc": "numpy.histogramdd(sample, bins=10, range=None, density=None, weights=None)\n\nCompute the multidimensional histogram of some data.\n\nParameters\n----------\nsample : (N, D) array, or (N, D) list of arrays\n    The data to be histogrammed.\n    Note the unusual interpretation of sample when an array_like:\n    * When an array, each row is a coordinate in a D-dimensional space - such as histogramdd(np.array([p1, p2, p3])).\n    * When a list of arrays, each array is the list of values for single coordinate - such as histogramdd([X, Y, Z]).\nbins : sequence or int, optional\n    The bin specification:\n    * A sequence of arrays describing the monotonically increasing bin edges along each dimension.\n    * The number of bins for each dimension (nx, ny, ... =bins)\n    * The number of bins for all dimensions (nx=ny=...=bins).\nrange : sequence, optional\n    A sequence of length D, each an optional (lower, upper) tuple giving the outer bin edges to be used if the edges are not given explicitly in bins.\ndensity : bool, optional\n    If False, the default, returns the number of samples in each bin. If True, returns the probability density function at the bin.\nweights : (N,) array_like, optional\n    An array of values w_i weighing each sample (x_i, y_i, z_i, ...).\n\nReturns\n-------\nH : ndarray\n    The multidimensional histogram of sample x.\nedges : list\n    A list of D arrays describing the bin edges for each dimension.",
      "code": "# Implementation in numpy/lib/_histograms_impl.py\n@array_function_dispatch(_histogramdd_dispatcher)\ndef histogramdd(sample, bins=10, range=None, density=None, weights=None):\n    \"\"\"\n    Compute the multidimensional histogram of some data.\n    \"\"\"\n    \n    try:\n        # Sample is an ND-array.\n        N, D = sample.shape\n    except (AttributeError, ValueError):\n        # Sample is a sequence of 1D arrays.\n        sample = np.atleast_2d(sample).T\n        N, D = sample.shape\n    \n    nbin = np.empty(D, np.intp)\n    edges = D*[None]\n    dedges = D*[None]\n    if weights is not None:\n        weights = np.asarray(weights)\n    \n    try:\n        M = len(bins)\n        if M != D:\n            raise ValueError(\n                'The dimension of bins must be equal to the dimension of the '\n                ' sample x.')\n    except TypeError:\n        # bins is an integer\n        bins = D*[bins]\n    \n    # normalize the range argument\n    if range is None:\n        range = (None,) * D\n    elif len(range) != D:\n        raise ValueError('range argument must have one entry per dimension')\n    \n    # Create edge arrays\n    for i in _range(D):\n        if np.ndim(bins[i]) == 0:\n            if bins[i] < 1:\n                raise ValueError(\n                    f'`bins[{i}]` must be positive, when an integer')\n            smin, smax = _get_outer_edges(sample[:,i], range[i])\n            try:\n                n = operator.index(bins[i])\n            except TypeError as e:\n                raise TypeError(\n                    \"`bins[{}]` must be an integer, when a scalar\".format(i)\n                ) from e\n            \n            edges[i] = np.linspace(smin, smax, n + 1)\n        elif np.ndim(bins[i]) == 1:\n            edges[i] = np.asarray(bins[i])\n            if np.any(edges[i][:-1] > edges[i][1:]):\n                raise ValueError(\n                    f'`bins[{i}]` must be monotonically increasing, when an '\n                    f'array')\n        else:\n            raise ValueError(\n                f'`bins[{i}]` must be a scalar or 1d array')\n        \n        nbin[i] = len(edges[i]) - 1\n        dedges[i] = np.diff(edges[i])\n    \n    # Compute the bin number each sample falls into.\n    Ncount = tuple(\n        # avoid np.digitize to work around gh-11022\n        np.searchsorted(edges[i], sample[:, i], side='right')\n        for i in _range(D)\n    )\n    \n    # Using digitize, values that fall on an edge are put in the right bin.\n    # For the rightmost bin, we want values equal to the right edge to be\n    # counted in the last bin, and not as an outlier.\n    for i in _range(D):\n        # Find which points are on the rightmost edge.\n        on_edge = (sample[:, i] == edges[i][-1])\n        # Shift these points one bin to the left.\n        Ncount[i][on_edge] -= 1\n    \n    # Compute the sample indices in the flattened histogram.\n    # This raises an error if the array is too large.\n    xy = np.ravel_multi_index(Ncount, nbin)\n    \n    # Compute the number of repetitions in xy and assign it to the\n    # flattened histmat.\n    hist = np.bincount(xy, weights, minlength=nbin.prod())\n    \n    # Shape into a proper matrix\n    hist = hist.reshape(nbin)\n    \n    # This preserves the (bad) behavior observed in gh-7845, for now.\n    hist = hist.astype(float, casting='safe')\n    \n    # Remove outliers (indices 0 and -1 for each dimension).\n    core = D*(slice(1, -1),)\n    hist = hist[core]\n    \n    if density:\n        # calculate the probability density function\n        s = hist.sum()\n        for i in _range(D):\n            shape = [1]*D\n            shape[i] = nbin[i] - 2\n            hist = hist / dedges[i].reshape(shape)\n        hist /= s\n    \n    return hist, edges"
    },
    {
      "name": "numpy.histogram_bin_edges",
      "category": "Histograms",
      "description": "Function to calculate only the edges of the bins used by the histogram function",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.histogram_bin_edges.html",
      "doc": "numpy.histogram_bin_edges(a, bins=10, range=None, weights=None)\n\nFunction to calculate only the edges of the bins used by the histogram function.\n\nParameters\n----------\na : array_like\n    Input data. The histogram is computed over the flattened array.\nbins : int or sequence of scalars or str, optional\n    If bins is an int, it defines the number of equal-width bins in the given range (10, by default). If bins is a sequence, it defines the bin edges, including the rightmost edge, allowing for non-uniform bin widths.\n    If bins is a string from the list below, histogram_bin_edges will use the method chosen to calculate the optimal bin width and consequently the number of bins.\nrange : (float, float), optional\n    The lower and upper range of the bins. If not provided, range is simply (a.min(), a.max()). Values outside the range are ignored.\nweights : array_like, optional\n    An array of weights, of the same shape as a. Each value in a only contributes its associated weight towards the bin count (instead of 1).\n\nReturns\n-------\nbin_edges : array of dtype float\n    The edges to pass into histogram",
      "code": "# Implementation in numpy/lib/_histograms_impl.py\n@array_function_dispatch(_histogram_bin_edges_dispatcher)\ndef histogram_bin_edges(a, bins=10, range=None, weights=None):\n    \"\"\"\n    Function to calculate only the edges of the bins used by the histogram\n    function.\n    \"\"\"\n    a, weights = _ravel_and_check_weights(a, weights)\n    bin_edges, _ = _get_bin_edges(a, bins, range, weights)\n    return bin_edges"
    },
    {
      "name": "numpy.digitize",
      "category": "Histograms",
      "description": "Return the indices of the bins to which each value in input array belongs",
      "url": "https://numpy.org/doc/stable/reference/generated/numpy.digitize.html",
      "doc": "numpy.digitize(x, bins, right=False)\n\nReturn the indices of the bins to which each value in input array belongs.\n\nIf values in x are beyond the bounds of bins, 0 or len(bins) is returned as appropriate.\n\nParameters\n----------\nx : array_like\n    Input array to be binned. Prior to NumPy 1.10.0, this array had to be 1-dimensional, but can now have any shape.\nbins : array_like\n    Array of bins. It has to be 1-dimensional and monotonic.\nright : bool, optional\n    Indicating whether the intervals include the right or the left bin edge. Default behavior is (right==False) indicating that the interval does not include the right edge.\n\nReturns\n-------\nindices : ndarray of ints\n    Output array of indices, of same shape as x.\n\nRaises\n------\nValueError\n    If bins is not monotonic.\nTypeError\n    If the type of the input is complex.\n\nNotes\n-----\nIf values in x are such that they fall outside the bin range, attempting to index bins with the indices that digitize returns will result in an IndexError.\n\nThe behavior of numpy.digitize is:\n\n    indices = digitize(x, bins)\n    for i in range(x.size):\n        if x[i] < bins[0]:\n            indices[i] = 0\n        elif x[i] >= bins[-1]:\n            indices[i] = len(bins)\n        else:\n            j = 1\n            while j < len(bins):\n                if x[i] < bins[j]:\n                    indices[i] = j\n                    break\n                j += 1",
      "code": "# C implementation for performance\n# Return the indices of the bins to which each value in input array belongs\n#\n# This function is implemented in C as part of NumPy's core multiarray module.\n# The C implementation provides:\n# - Optimized memory access patterns\n# - Efficient array manipulation\n# - Low-level control over data layout\n# - Integration with NumPy's array object internals\n#\n# Source: # C implementation in numpy/_core/src/multiarray/compiled_base.c\n# Python wrapper:\n@array_function_dispatch(_digitize_dispatcher)\ndef digitize(x, bins, right=False):\n    \"\"\"\n    Return the indices of the bins to which each value in input array belongs.\n    \"\"\"\n    x = _nx.asarray(x)\n    bins = _nx.asarray(bins)\n    \n    # Check for complex dtypes\n    if x.dtype.kind == 'c':\n        raise TypeError(\"x may not be complex\")\n    \n    mono = _monotonicity(bins)\n    if mono == 0:\n        raise ValueError(\"bins must be monotonically increasing or decreasing\")\n    \n    # Check for NaN in bins, as this would break the algorithm\n    if _nx.isnan(bins).any():\n        raise ValueError(\"bins may not contain NaN\")\n    \n    if mono == -1:\n        # Reverse bins and invert result\n        return len(bins) - _nx._core.multiarray._digitize(x, bins[::-1], not right)\n    else:\n        return _nx._core.multiarray._digitize(x, bins, right)"
    }
  ]
}